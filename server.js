const express = require('express');
const tf = require('@tensorflow/tfjs-node');
const multer = require('multer');
const sharp = require('sharp');
const cors = require('cors');
const path = require('path');

const app = express();
const PORT = process.env.PORT || 3000;

app.use(cors());
app.use(express.json());

const upload = multer({ limits: { fileSize: 10 * 1024 * 1024 } });

let model = null;
let loaded = false;

async function loadModel() {
  try {
    console.log('Loading model...');
    const modelPath = path.join(__dirname, 'model.json');
    model = await tf.loadLayersModel(`file://${modelPath}`);
    loaded = true;
    console.log('Model loaded successfully!');
  } catch (error) {
    console.error('Model load error:', error);
  }
}

function generateReading(hand) {
  const readings = {
    'left': 'Your left hand reveals inner potential and creativity.',
    'right': 'Your right hand shows drive and determination.'
  };
  return readings[hand] || 'Great energy detected in your palm.';
}

app.get('/', (req, res) => {
  res.json({ status: 'OK', loaded: loaded });
});

app.get('/health', (req, res) => {
  res.json({ status: loaded ? 'healthy' : 'loading' });
});

app.post('/analyze-palm', upload.single('image'), async (req, res) => {
  if (!loaded) return res.status(503).json({ error: 'Model loading' });
  if (!req.file) return res.status(400).json({ error: 'No image' });
  
  try {
    const buffer = await sharp(req.file.buffer).resize(224, 224).raw().toBuffer();
    const array = new Float32Array(buffer.length);
    for (let i = 0; i < buffer.length; i++) array[i] = buffer[i] / 255.0;
    
    const tensor = tf.tensor4d(array, [1, 224, 224, 3]);
    const prediction = await model.predict(tensor).data();
    const confidence = Math.max(prediction[0], 1 - prediction[0]) * 100;
    const hand = prediction[0] > 0.5 ? 'right' : 'left';
    const handJa = prediction[0] > 0.5 ? 'å³æ‰‹' : 'å·¦æ‰‹';
    
    const reading = generateReading(hand);
    
    res.json({
      success: true,
      hand: handJa,
      handEn: hand,
      confidence: Math.round(confidence),
      palmReading: reading,
      lineMessage: `${handJa}ã‚’æ¤œå‡ºï¼ç¢ºä¿¡åº¦: ${Math.round(confidence)}%\n\n${reading}`
    });
    
    tensor.dispose();
  } catch (error) {
    res.status(500).json({ error: error.message });
  }
});

app.post('/test-webhook', (req, res) => {
  res.json({ success: true, message: 'Test OK', data: req.body });
});
app.post('/line-webhook', async (req, res) => {
  try {
    const events = req.body.events || [];
    
    for (const event of events) {
      if (event.type === 'message') {
        if (event.message.type === 'image') {
          await handlePalmReading(event);
        } else if (event.message.type === 'text') {
          await handleTextMessage(event);
        }
      }
    }
    
    res.sendStatus(200);
  } catch (error) {
    console.error('LINE webhook error:', error);
    res.sendStatus(500);
  }
});

// ç”»åƒãƒ¡ãƒƒã‚»ãƒ¼ã‚¸å‡¦ç†ï¼ˆæ‰‹ç›¸é‘‘å®šï¼‰
async function handlePalmReading(event) {
  try {
    // 1. LINEç”»åƒå–å¾—
    const imageResponse = await fetch(
      `https://api-data.line.me/v2/bot/message/${event.message.id}/content`,
      {
        headers: { 'Authorization': `Bearer ${process.env.LINE_ACCESS_TOKEN}` }
      }
    );
    
    if (!imageResponse.ok) {
      throw new Error('Failed to get image from LINE');
    }
    
    const imageBuffer = await imageResponse.arrayBuffer();
    
    // 2. æ—¢å­˜ã®palmè§£æAPIã‚’å†…éƒ¨å‘¼ã³å‡ºã—ï¼ˆmulterã‚’ä½¿ã‚ãšã«ç›´æ¥å‡¦ç†ï¼‰
   const buffer = await sharp(Buffer.from(imageBuffer)).resize(224, 224).raw().toBuffer();
const array = new Float32Array(buffer.length);
for (let i = 0; i < buffer.length; i++) {
  array[i] = buffer[i] / 255.0;    }
    
    // TensorFlowãƒ¢ãƒ‡ãƒ«ã§äºˆæ¸¬ï¼ˆæ—¢å­˜ã®ãƒ­ã‚¸ãƒƒã‚¯ã‚’ä½¿ç”¨ï¼‰
    if (!loaded) {
      throw new Error('Model not loaded');
    }
    
    const tensor = tf.tensor4d(array, [1, 224, 224, 3]);
    const prediction = await model.predict(tensor).data();
    const confidence = Math.max(prediction[0], 1 - prediction[0]) * 100;
    const hand = prediction[0] > 0.5 ? 'right' : 'left';
    const handJa = prediction[0] > 0.5 ? 'å³æ‰‹' : 'å·¦æ‰‹';
    
    const palmData = {
      success: true,
      hand: handJa,
      handEn: hand,
      confidence: Math.round(confidence),
      palmReading: generateReading(hand)
    };
    
    // 3. ChatGPTé‘‘å®š
    const fortuneResult = await getChatGPTFortune(palmData);
    
    // 4. LINEè¿”ä¿¡
    await replyToLine(event.replyToken, fortuneResult);
    
  } catch (error) {
    console.error('Palm reading error:', error);
    await replyToLine(event.replyToken, 
      'ç”³ã—è¨³ã”ã–ã„ã¾ã›ã‚“ã€‚æ‰‹ç›¸ã®è§£æä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚ğŸ™\n\n' +
      'ğŸ“¸ æ’®å½±ã®ã‚³ãƒ„ï¼š\n' +
      'â€¢ æ˜ã‚‹ã„å ´æ‰€ã§æ’®å½±\n' +
      'â€¢ æ‰‹ã®ã²ã‚‰å…¨ä½“ãŒå†™ã‚‹ã‚ˆã†ã«\n' +
      'â€¢ ãƒ”ãƒ³ã¼ã‘ã—ãªã„ã‚ˆã†æ³¨æ„\n\n' +
      'ã‚‚ã†ä¸€åº¦ãŠè©¦ã—ãã ã•ã„ã€‚'
    );
  }
}

// ãƒ†ã‚­ã‚¹ãƒˆãƒ¡ãƒƒã‚»ãƒ¼ã‚¸å‡¦ç†
async function handleTextMessage(event) {
  const text = event.message.text.toLowerCase();
  let replyText = '';
  
  if (text.includes('ã“ã‚“ã«ã¡') || text.includes('ã¯ã˜ã‚') || text.includes('hello')) {
    replyText = 'ã“ã‚“ã«ã¡ã¯ï¼æ‰‹ç›¸é‘‘å®šbotã§ã™âœ‹\n\n' +
               'æ‰‹ã®ã²ã‚‰ã®å†™çœŸã‚’é€ã£ã¦ã„ãŸã ã‘ã‚Œã°ã€AIåˆ†æã«ã‚ˆã‚‹è©³ã—ã„æ‰‹ç›¸é‘‘å®šã‚’ãŠè¿”ã—ã—ã¾ã™ã€‚\n\n' +
               'ğŸ“ æ’®å½±ã®ã‚³ãƒ„ï¼š\n' +
               'â€¢ æ˜ã‚‹ã„å ´æ‰€ã§æ’®å½±\n' +
               'â€¢ æ‰‹ã®ã²ã‚‰å…¨ä½“ãŒå†™ã‚‹ã‚ˆã†ã«\n' +
               'â€¢ ãƒ”ãƒ³ã¼ã‘ã—ãªã„ã‚ˆã†æ³¨æ„\n\n' +
               'ãã‚Œã§ã¯ã€ãŠæ‰‹ç›¸ã‚’æ‹è¦‹ã•ã›ã¦ã„ãŸã ãã¾ã™ã­ï¼ğŸ”®';
  } else if (text.includes('ä½¿ã„æ–¹') || text.includes('ãƒ˜ãƒ«ãƒ—') || text.includes('help')) {
    replyText = 'ğŸ“‹ æ‰‹ç›¸é‘‘å®šbotã®ä½¿ã„æ–¹\n\n' +
               '1ï¸âƒ£ æ‰‹ã®ã²ã‚‰ã®å†™çœŸã‚’æ’®å½±\n' +
               '2ï¸âƒ£ ã“ã®ãƒãƒ£ãƒƒãƒˆã«å†™çœŸã‚’é€ä¿¡\n' +
               '3ï¸âƒ£ AIåˆ†æã«ã‚ˆã‚‹é‘‘å®šçµæœã‚’ãŠè¿”ã—ã—ã¾ã™\n\n' +
               'ğŸ’¡ ã‚ˆã‚Šæ­£ç¢ºãªé‘‘å®šã®ãŸã‚ã«ï¼š\n' +
               'â€¢ è‡ªç„¶å…‰ã§æ’®å½±ï¼ˆå®¤å†…ç¯ã§ã‚‚OKï¼‰\n' +
               'â€¢ æ‰‹ã‚’å¹³ã‚‰ã«åºƒã’ã¦\n' +
               'â€¢ æŒ‡å…ˆã‹ã‚‰æ‰‹é¦–ã¾ã§å…¨ä½“ã‚’å†™ã™\n' +
               'â€¢ ãƒ–ãƒ¬ãªã„ã‚ˆã†å›ºå®šã—ã¦æ’®å½±\n\n' +
               'æº–å‚™ãŒã§ãã¾ã—ãŸã‚‰ã€å†™çœŸã‚’ãŠé€ã‚Šãã ã•ã„ğŸ“·';
  } else {
    replyText = 'ãŠç–²ã‚Œã•ã¾ã§ã™ï¼âœ¨\n\n' +
               'æ‰‹ç›¸é‘‘å®šã‚’ã”å¸Œæœ›ã§ã—ãŸã‚‰ã€æ‰‹ã®ã²ã‚‰ã®å†™çœŸã‚’é€ã£ã¦ãã ã•ã„ã­ğŸ“¸\n\n' +
               'ä½¿ã„æ–¹ãŒåˆ†ã‹ã‚‰ãªã„å ´åˆã¯ã€Œãƒ˜ãƒ«ãƒ—ã€ã¨é€ä¿¡ã—ã¦ãã ã•ã„ã€‚';
  }
  
  await replyToLine(event.replyToken, replyText);
}

// ChatGPTé‘‘å®š
async function getChatGPTFortune(palmData) {
  try {
    const prompt = `
æ‰‹ç›¸é‘‘å®šã‚’ãŠé¡˜ã„ã—ã¾ã™ã€‚

ã€è§£æãƒ‡ãƒ¼ã‚¿ã€‘
æ‰‹: ${palmData.hand}
ä¿¡é ¼åº¦: ${palmData.confidence}%
åŸºæœ¬é‘‘å®š: ${palmData.palmReading}

ã€é‘‘å®šã‚¹ã‚¿ã‚¤ãƒ«ã€‘
- æ¸©ã‹ãè¦ªã—ã¿ã‚„ã™ã„é–¢è¥¿å¼æ··ã˜ã‚Šã®å£èª¿
- ã¾ãšè‰¯ã„é¢ã‚’ä¼ãˆã¦ã‹ã‚‰ã€å»ºè¨­çš„ãªã‚¢ãƒ‰ãƒã‚¤ã‚¹
- å…·ä½“çš„ã§å®Ÿè·µçš„ãªå†…å®¹ã‚’å«ã‚ã‚‹
- å¸Œæœ›ã‚’æŒã¦ã‚‹ã‚ˆã†ãªå‰å‘ããªçµè«–ã§ç· ã‚ã‚‹

ã€å«ã‚ã¦ã»ã—ã„å†…å®¹ã€‘
ğŸŒŸ ã‚ãªãŸã®æ‰‹ç›¸ã®ç‰¹å¾´
ğŸ’ª ç”Ÿå‘½ç·šï¼šå¥åº·é‹ãƒ»ç”Ÿå‘½åŠ›
ğŸ§  çŸ¥èƒ½ç·šï¼šæ‰èƒ½ãƒ»é©è·
â¤ï¸ æ„Ÿæƒ…ç·šï¼šæ‹æ„›ãƒ»äººé–“é–¢ä¿‚
ğŸ€ ç·åˆé‹ã¨ã‚¢ãƒ‰ãƒã‚¤ã‚¹

ã€æ–‡å­—æ•°ã€‘400-500æ–‡å­—ç¨‹åº¦

è¦ªèº«ã«ãªã£ã¦é‘‘å®šã—ã¦ãã ã•ã„ã€‚
`;

    const response = await fetch('https://api.openai.com/v1/chat/completions', {
      method: 'POST',
      headers: {
        'Authorization': `Bearer ${process.env.OPENAI_API_KEY}`,
        'Content-Type': 'application/json'
      },
      body: JSON.stringify({
        model: 'gpt-4',
        messages: [
          {
            role: 'system',
            content: 'ã‚ãªãŸã¯30å¹´ã®çµŒé¨“ã‚’æŒã¤è¦ªã—ã¿ã‚„ã™ã„æ‰‹ç›¸é‘‘å®šå¸«ã§ã™ã€‚æ¸©ã‹ãã€å¸Œæœ›ã«æº€ã¡ãŸé‘‘å®šã‚’å¿ƒãŒã‘ã¦ã„ã¾ã™ã€‚'
          },
          {
            role: 'user',
            content: prompt
          }
        ],
        max_tokens: 800,
        temperature: 0.7
      })
    });
    
    if (!response.ok) {
      throw new Error(`ChatGPT API failed: ${response.status}`);
    }
    
    const result = await response.json();
    return result.choices[0].message.content;
    
  } catch (error) {
    console.error('ChatGPT error:', error);
    return `${palmData.hand}ã®æ‰‹ç›¸ã‚’æ‹è¦‹ã•ã›ã¦ã„ãŸã ãã¾ã—ãŸâœ‹\n\n` +
           `${palmData.palmReading}\n\n` +
           `ä¿¡é ¼åº¦: ${palmData.confidence}%\n\n` +
           `â€»ã‚ˆã‚Šè©³ã—ã„é‘‘å®šã¯å¾Œã»ã©ãŠè¿”ã—ã„ãŸã—ã¾ã™ã€‚ã—ã°ã‚‰ããŠå¾…ã¡ãã ã•ã„ã€‚`;
  }
}

// LINEè¿”ä¿¡
async function replyToLine(replyToken, message) {
  try {
    const response = await fetch('https://api.line.me/v2/bot/message/reply', {
      method: 'POST',
      headers: {
        'Authorization': `Bearer ${process.env.LINE_ACCESS_TOKEN}`,
        'Content-Type': 'application/json'
      },
      body: JSON.stringify({
        replyToken: replyToken,
        messages: [{
          type: 'text',
          text: message
        }]
      })
    });
    
    if (!response.ok) {
      throw new Error(`LINE reply failed: ${response.status}`);
    }
  } catch (error) {
    console.error('LINE reply error:', error);
  }
}
loadModel().then(() => {

  app.listen(PORT, () => console.log(`Server: ${PORT}`));
});
